# -*- coding: utf-8 -*-
"""Legal_Text_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/191B1AaecscBS8DvL8IMhB2DMwrPtAH1K
"""

import numpy as np
import pandas as pd
import underthesea
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

df1 =pd.read_excel(r"C:\Users\DELL\Downloads\Bo_luat_Doanh_Nghiep_final.xlsx")
df2 =pd.read_excel(r"C:\Users\DELL\Downloads\Bo_luat_Lao_Dong_final.xlsx")
df3 =pd.read_excel(r"C:\Users\DELL\Downloads\Bo_luat_Dan_su_final.xlsx")

df=pd.merge(df1, df2, how="outer").merge(df3, how="outer")

df

df.info()

df

def containDigit(iword):
    return any(ch.isdigit() for ch in iword)

def containUpperLetterButNotFirst(iword):
    if(iword.isupper()):
        return True
    for i in range(1, len(iword)):
        if(iword[i].isupper() and iword[i-1]!=' '):
            return False
    return True

def FeatureFunction1(w): # Chỉ lọc những từ không hợp lệ có độ dài từ 3 kí tự trở xuống VÀ có chứa số VÀ có chữ cái viết hoa không chuẩn (viết hoa không phải kí tự đầu)
    return len(w) > 3 and not containDigit(w) and containUpperLetterButNotFirst(w)

for i in range(len(df["Điều"])):
  lwt = underthesea.word_tokenize(df["Điều"].iloc[i].replace("'","").replace("\"",""))
  lwtl = [w for w in lwt if FeatureFunction1(w)]
  df.loc[i, "Điều"] = " | ".join(lwtl)

for i in range(len(df["Nội dung"])):
  lwc = underthesea.word_tokenize(df["Nội dung"].iloc[i].replace("'","").replace("\"",""))
  lwcl = [w for w in lwc if FeatureFunction1(w)]
  df.loc[i, "Nội dung"] = " | ".join(lwcl)

df.info()

df['Bộ luật'].unique()

display(df)

combined_df_by_category = df.groupby('Bộ luật').agg({
    'Điều': lambda x: ' | '.join(x),
    'Nội dung': lambda x: ' | '.join(x)
}).reset_index()

display(combined_df_by_category)

"""1. Tạo một bảng dữ liệu trong đó, mỗi từ là một feature, và giá trị của nó là số lần xuất hiện của nó. Có thể cộng cả content+title lại. Tiếp đến feed bảng dữ liệu này vào 3 mô hình học máy của scikit (Logistic, SVM, NaiveBayes)

2. Làm tương tự ở 1, nhưng bảng dữ liệu với số thuộc tính giảm sau khi loại các từ xuất hiện chung trong nhiều nhóm (có thể sử dụng set kết hợp với intersect - phép giao). Bảng features này có kích thước nhỏ hơn nhiều so với bảng 1.

3. Không tạo bảng features như 1 và 2 mà sử dụng kĩ thuật BoW (trong scikit, sử dụng CountVectorize)

4. Không tạo bảng feature như 1 và 2 mà sử dụng tfidf (TfidfVectorizer của scikit)

***Câu 1: xử lý thông thường, dùng tất cả các word hợp lệ (không lấy số, các từ có độ dài từ bé hơn hoặc bằng 3 kí tự)***
"""

for i in range(len(df["Nội dung"])):
  df.loc[i, "text"] = str(df["Nội dung"][i] + " | " + df['Điều'][i])

combined_df=df.drop(labels=["Điều", "Nội dung"], axis=1)

display(combined_df)

def TrainModel(model, _X_train, _X_test, _y_train, _y_test):
    model.fit(_X_train, _y_train)

    y_pred = model.predict(_X_test)

    acc = accuracy_score(_y_test, y_pred)
    prec = precision_score(_y_test, y_pred, average='macro', zero_division=0)
    rec = recall_score(_y_test, y_pred, average='macro', zero_division=0)
    f1 = f1_score(_y_test, y_pred, average='macro', zero_division=0)
    print(f"Model {model} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}")

    return model

def predict_code(s, model, vocab_):
    w_vi = " | ".join(underthesea.word_tokenize(s))
    vector_input = pd.DataFrame(np.zeros([1, len(vocab_)]), columns=vocab_)
    for word in vocab_:
        vector_input.loc[0, word] = w_vi.lower().count(word.lower())
    result = model.predict(vector_input)
    return {s: result[0]}

"""**Cách 1. Sử dụng BoW**"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import make_pipeline

corpus = combined_df['text'].astype(str).tolist()
corpus_norm = [w.replace(" ", "_").replace("_|_", " ") for w in corpus] # Thay đổi biểu diễn chuỗi "Bầu trời | trong xanh" thành "Bầu_trời trong_xanh"
y_cv = combined_df['Bộ luật']

X_train_text, X_test_text, y_train_cv, y_test_cv = train_test_split(corpus_norm, y_cv, test_size=0.3, random_state=42)

pipe_logistic = make_pipeline(CountVectorizer(), LogisticRegression(solver='liblinear', random_state=42))
pipe_svm = make_pipeline(CountVectorizer(), SVC(kernel='sigmoid'))
pipe_nb = make_pipeline(CountVectorizer(), MultinomialNB())

pipe_logistic.fit(X_train_text, y_train_cv)
pipe_svm.fit(X_train_text, y_train_cv)
pipe_nb.fit(X_train_text, y_train_cv)

def eval_pipeline(pipe, X_test, y_test):
    y_pred = pipe.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)
    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)
    print(f"Model {pipe.steps[-1][1].__class__.__name__} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}")

eval_pipeline(pipe_logistic, X_test_text, y_test_cv)
eval_pipeline(pipe_svm, X_test_text, y_test_cv)
eval_pipeline(pipe_nb, X_test_text, y_test_cv)

vectorized_logistic = pipe_logistic
vectorized_svm = pipe_svm
vectorized_nb = pipe_nb

input_list = ["Người lao động khi đại diện cho doanh nghiệp ký kết giao dịch dân sự phải bảo đảm rằng quyền và nghĩa vụ phát sinh từ thỏa thuận không vượt quá phạm vi được ủy quyền.",
              "Khi công ty tạm ngừng hoạt động để khắc phục rủi ro pháp lý, người sử dụng lao động phải thông báo cho người lao động theo quy trình được quy định trong các giao dịch dân sự liên quan.",
              "Một hợp đồng lao động được ký kết giữa cá nhân và công ty nhưng nội dung lại mang tính điều chỉnh quan hệ dân sự thì phải làm rõ trách nhiệm của pháp nhân trước khi công bố quyết định quản trị."]

def predict_code_pipeline(s, pipe):
    w_vi = " | ".join(underthesea.word_tokenize(s)).replace(" ", "_").replace("_|_", " ")  # Thay đổi biểu diễn chuỗi "Bầu trời | trong xanh" thành "Bầu_trời trong_xanh"
    result = pipe.predict([w_vi])
    return {s: result[0]}

for s in input_list:
    print("Logistics: ", predict_code_pipeline(s, vectorized_logistic))

for s in input_list:
    print("SVM: ", predict_code_pipeline(s, vectorized_svm))

for s in input_list:
    print("NB: ", predict_code_pipeline(s, vectorized_nb))

"""**Cách 2.Sử dụng Tfidf**"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline

tfidf_logistic = make_pipeline(TfidfVectorizer(), LogisticRegression(solver='liblinear', random_state=42))
tfidf_svm = make_pipeline(TfidfVectorizer(), SVC(kernel='sigmoid'))
tfidf_nb = make_pipeline(TfidfVectorizer(), MultinomialNB())

tfidf_logistic.fit(X_train_text, y_train_cv)
tfidf_svm.fit(X_train_text, y_train_cv)
tfidf_nb.fit(X_train_text, y_train_cv)

eval_pipeline(tfidf_logistic, X_test_text, y_test_cv)
eval_pipeline(tfidf_svm, X_test_text, y_test_cv)
eval_pipeline(tfidf_nb, X_test_text, y_test_cv)

for s in input_list:
    print("Logistic: ", predict_code_pipeline(s, tfidf_logistic))
print()
for s in input_list:
    print("SVM: ", predict_code_pipeline(s, tfidf_svm))
print()
for s in input_list:
    print("NB: ", predict_code_pipeline(s, tfidf_nb))

"""Thử dự đoán ra Điều và Bộ luật"""

df

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd
import numpy as np
import re

df_up = df.copy()

# ----- TRAIN MODEL DỰ BÁO BỘ LUẬT -----

# X = Nội dung, y = Bộ luật
X = df_up["Nội dung"].astype(str)
y = df_up["Bộ luật"].astype(str)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

clf = make_pipeline(
    CountVectorizer(),
    LogisticRegression(solver="liblinear", random_state=42)
)

clf.fit(X_train, y_train)

print("Accuracy:", accuracy_score(y_test, clf.predict(X_test)))
print(classification_report(y_test, clf.predict(X_test)))

# Tách mỗi “Điều ... | Điều ...” thành từng dòng
expanded_rows = []

for idx, row in df_up.iterrows():
    bo_luat = row["Bộ luật"]
    noi_dung = row["Nội dung"]

    list_dieu = [d.strip() for d in row["Điều"].split("|")]

    for d in list_dieu:
        expanded_rows.append([bo_luat, d, noi_dung])

df_expanded = pd.DataFrame(expanded_rows, columns=["Bộ luật", "Điều", "Nội dung"])

tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df_expanded["Nội dung"])

from sklearn.metrics.pairwise import cosine_similarity

def recommend_dieu(text_input, predicted_law, top_n=3):

    # Chỉ lọc các điều trong bộ luật phù hợp
    mask = (df["Bộ luật"] == predicted_law).values
    df_sub = df_expanded[mask]

    # Vectorize câu input
    q_vec = tfidf.transform([text_input])

    # Tính cosine similarity
    sim = cosine_similarity(q_vec, tfidf_matrix[mask])[0]

    # Lấy top-N điều phù hợp
    top_idx = np.argsort(sim)[-top_n:][::-1]

    return df_sub.iloc[top_idx][["Điều", "Bộ luật"]]

import pandas as pd
pd.set_option("display.max_colwidth", None)

from IPython.display import display

def predict_full(text):
    # 1. Dự báo bộ luật
    predicted_law = clf.predict([text])[0]

    # 2. Gợi ý điều liên quan
    recommended = recommend_dieu(text, predicted_law, top_n=3)

    if recommended is not None and len(recommended) > 0:
        recommended = recommended.reset_index(drop=True)

        print("Bộ luật dự báo:", predicted_law)
        print("Các điều phù hợp nhất:")
        display(recommended)   # <-- QUAN TRỌNG
    else:
        print("Bộ luật dự báo:", predicted_law)
        print("Không tìm thấy điều phù hợp.")

predict_full("Người lao động khi đại diện cho doanh nghiệp ký kết giao dịch dân sự phải bảo đảm rằng quyền và nghĩa vụ phát sinh từ thỏa thuận không vượt quá phạm vi được ủy quyền.")